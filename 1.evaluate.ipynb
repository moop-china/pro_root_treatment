{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 介绍\n",
    "在深度学习中，需要大量的计算，我们经常被硬件条件所限制，所以在别人的模型基础上进行修改优化，成了很多人的选择，这相当于是一场接力赛，我们在著名的模型基础上，接过接力棒，做我们想做的事情。如果没有这个接力的过程，普通人想学习深度学习，并有所成果，时间和人力成本将高出很多。\n",
    "\n",
    "本实验，我们提供了已经训练好的模型，并不进行进一步的训练，而是转向对训练成果进行评估。\n",
    "\n",
    "本课将加载已有的模型，来对牙齿的根管治疗中的牙齿部分和根管部分来进行检测，然后将预测结果储存起来，并在图像上画出代表标注的矩形框。这是深度学习和医学的结合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import imgaug as ia\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "\n",
    "from dataset import voc\n",
    "from retinanet import model, val\n",
    "from retinanet import transforms as aug\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 初始化\n",
    "## 2.1 设定常量\n",
    "这些常量在接下来的程序中都不需要，也不能随便改动。\n",
    "\n",
    "下面进行简单的解释：\n",
    "1. root_path：数据根目录\n",
    "2. img_path：图像路径\n",
    "3. result_path：模型和预测结果的储存路径\n",
    "4. model_name：要加载的模型名称\n",
    "5. image_size：预测用的图像大小，我们要将原图变换到模型采用的大小\n",
    "6. max_detections：一张图像中最多预测的标注数量\n",
    "7. num_classes：总的类别数量，分别是牙齿和根管"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "root_path = './data'\n",
    "img_path = \"./data/JPEGImages\"\n",
    "result_path = './result'\n",
    "model_name = \"root_treatment\"\n",
    "\n",
    "image_size=512\n",
    "max_detections = 4\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 加载模型和数据\n",
    "我们的任务是进行预测（evaluate），所以将数据集data_set命名为val_set。这里val_set是一个可迭代对象，里面加载了`./data/ImageSets/Main/val_list.txt`中记录的数据，其中图像从`img_path`加载，人工的标注从`./data/Annotation`中加载。\n",
    "\n",
    "同时，图像在加载的过程中，会通过`val_trans`的一系列变换，依次进行下面的操作：\n",
    "1. 补全图像为正方形\n",
    "2. 将图像修改为长宽512大小\n",
    "3. 修改图像色阶，对比度\n",
    "4. 将图像转化成pytorch认可的tensor格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_trans = aug.Compose([\n",
    "    aug.Pad(),\n",
    "    aug.Resize(image_size, image_size),\n",
    "    aug.AutoLevel(min_level_rate=1, max_level_rate=1),\n",
    "    aug.AutoContrast(),\n",
    "    aug.Contrast(1.25),\n",
    "    aug.ToTensor()\n",
    "])\n",
    "\n",
    "val_set = voc.VOCDetection(\n",
    "    root_path,\n",
    "    image_set=\"val_list\",\n",
    "    transforms=val_trans\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们对数据集进行观察。val_set可以直接取下标，我们选择第一个内容进行观察。\n",
    "\n",
    "他的每一个元素都是(tensor, ([labels], [annnotations], {pad_loc, scale}))格式。\n",
    "\n",
    "其中annnotations是一个list，里面有四个数字，分别代表了标注框的左上角横纵坐标，右下角横纵坐标。注意，我们的坐标计算都是以*最左上角为原点*的。\n",
    "\n",
    "pad_loc记录了我们之前对图形进行的pad变换，这里的[70, 70, 0, 0]代表了上下都填充了70像素，而左右并没有改变。\n",
    "\n",
    "scale记录了我们之前对图形进行的resize变化，这里的表示原图是新图的0.8258064516129032大小。注意这里说的原图，是已经被pad操作处理过的正方形图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数据有了直观的概念后，我们加载模型root_treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load(os.path.join(result_path, model_name + \".pth\"), map_location='cpu')\n",
    "device = torch.device(\"cpu\")\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 进行预测\n",
    "下面这个函数就是预测是关键了，我们在函数里面用注释来做讲解。这里介绍还没有介绍的参数含义：\n",
    "1. score_threshold：网络预测结果的衡量标准。网络会对每一个预测进行评估，代表了他的自信程度，比如0.9代表他很自信这个结果是正确的，0.4代表他很不确定结果的正确性。我们在这里设置的目的是告诉网络，我们只需要看你觉得自信程度高于score_threshold的结果，其他的你自己留着\n",
    "2. save_path：预测结果的保存路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_detections(dataset, retinanet, num_classes=2, score_threshold=0.5, max_detections=4, save_path=None, model_name=None):\n",
    "    # 准备一个可以容纳全部数据的多维list\n",
    "    all_detections = [[None for i in range(num_classes)] for j in range(len(dataset))]\n",
    "    \n",
    "    # 模型初始化，这里有个参数，我们在第三个课程中会看到他的作用。\n",
    "    retinanet.eval()\n",
    "    retinanet.set_nms(0.7)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for index in range(len(dataset)):\n",
    "            # data是我们之前看到的复杂结构 (img, ([labels], [gts], {scale, pad_loc...}))\n",
    "            data = dataset[index]\n",
    "            # get scale\n",
    "            scale = data[1][2][\"scale\"]\n",
    "            # get pad loc, up, down, left, right\n",
    "            pad_loc = data[1][2][\"pad_loc\"]\n",
    "\n",
    "            # 我们将图像作为参数传入神经网络中，他将返回三个值，分别是\n",
    "            # score 网络对这次预测的自信程度，labels网络认为他的类别， boxes网络预测出的标注坐标\n",
    "#             scores, labels, boxes = retinanet(data[0].permute(0, 1, 2).cuda().float().unsqueeze(dim=0))\n",
    "            scores, labels, boxes = retinanet(data[0].permute(0, 1, 2).to(device).float().unsqueeze(dim=0))\n",
    "            scores = scores.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            boxes  = boxes.cpu().numpy()\n",
    "            \n",
    "            # 由于模型需要用512的图像进行预测，所以这里我们为了得到原图，进行了一些反变换\n",
    "            # correct boxes for image scale\n",
    "            boxes /= scale\n",
    "            for bbx in boxes:\n",
    "                # height fix\n",
    "                bbx[1] -= pad_loc[0]\n",
    "                bbx[3] -= pad_loc[0]\n",
    "                # width fix\n",
    "                bbx[0] -= pad_loc[2]\n",
    "                bbx[2] -= pad_loc[2]\n",
    "            \n",
    "            # 这里我们将选择score > score_threshold的预测结果。然后我们将结果写入all_detections中\n",
    "            indices = np.where(scores > score_threshold)[0]\n",
    "            if indices.shape[0] > 0:\n",
    "                # select those scores\n",
    "                scores = scores[indices]\n",
    "\n",
    "                # find the order with which to sort the scores\n",
    "                scores_sort = np.argsort(-scores)[:max_detections]\n",
    "\n",
    "                # select detections\n",
    "                image_boxes      = boxes[indices[scores_sort], :]\n",
    "                image_scores     = scores[scores_sort]\n",
    "                image_labels     = labels[indices[scores_sort]]\n",
    "                image_detections = np.concatenate([image_boxes, np.expand_dims(image_scores, axis=1), np.expand_dims(image_labels, axis=1)], axis=1)\n",
    "                                \n",
    "                # copy detections to all_detections\n",
    "                for label in range(num_classes):\n",
    "                    all_detections[index][label] = image_detections[image_detections[:, -1] == label, :-1]\n",
    "            else:\n",
    "                # copy detections to all_detections\n",
    "                for label in range(num_classes):\n",
    "                    all_detections[index][label] = np.zeros((0, 5))\n",
    "            \n",
    "            # 我们每次处理完都进行一次输出，让我们对网络的预测进展有个直观的了解\n",
    "            print(\"\\r {}/{}\".format(index + 1, len(dataset)), end='')\n",
    "    \n",
    "    # 将结果保存到save_path下的csv中，为了区分不同的csv，我们将传入的参数作为csv的名字的一部分\n",
    "    if save_path:\n",
    "        csv_data = pd.DataFrame(columns=['id', 'serial', 'class', 'x1', 'y1', 'x2', 'y2', 'prob'])\n",
    "        csv_id = 0\n",
    "        for index in range(len(all_detections)):\n",
    "            image_name = dataset.images[index].split('/')[-1].split('.')[0]\n",
    "            for label in range(len(all_detections[index])):\n",
    "                for box in range(len(all_detections[index][label])):\n",
    "                    bbx = all_detections[index][label][box]\n",
    "                    csv_data.loc[csv_id] = [image_name, box, label, bbx[0], bbx[1], bbx[2], bbx[3], bbx[4]]\n",
    "                    csv_id += 1\n",
    "        file_name = \"{}_{}\".format(\n",
    "            model_name,\n",
    "            score_threshold,\n",
    "        )\n",
    "        csv_data.to_csv(os.path.join(save_path, file_name+\".csv\"))\n",
    "    \n",
    "    return all_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们就可以指定score_threshold，让网络输出他的结果了。我们将结果放在模型的同级目录下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_thresholds = [0.5, 0.55, 0.6]\n",
    "score_threshold = score_thresholds[0]\n",
    "all_detections = _get_detections(val_set, net, num_classes=num_classes, score_threshold=score_threshold, max_detections=max_detections, save_path=result_path, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 观察结果\n",
    "将结果保存到文件中是方便我们以后的观察，当图像少的时候，比如这里我们只有49张，我们可以很快预测完，但是当图像数量太多的时候，需要运行很久。这时候，如果已经保存了之前的结果，那么我们不需要再运行便可以进行观察，或者进行其他的操作了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(img_pd, img_path=None):\n",
    "    # 接受一个 pandas 的 dataframe，以及原始图像的路径\n",
    "    # 因为dataframe中，每一行代表一个预测框，而我们的处理单位是一张图，一张图上最多有4个框。所以这里将所有的图像名字取出\n",
    "    name_series = img_pd.drop_duplicates(subset='id', inplace=False)['id']\n",
    "    \n",
    "    for image_name in name_series:\n",
    "        # 按照图像名称进行迭代，选择图像名称为image_name的全部框\n",
    "        img_some = img_pd[img_pd['id'] == image_name]\n",
    "        \n",
    "        # 如果是只想看类型为0的框，可以自行选择将下面一行取消注释\n",
    "#         img_some = img_some[img_some['class'] == 0]\n",
    "        \n",
    "        img = Image.open(os.path.join(img_path, image_name + \".jpg\"))\n",
    "        np_img = np.asarray(img)\n",
    "        \n",
    "        # 对于每一个图中的框，将其画在图像上，颜色 RGB = [0, 255, 0]，粗细为 2 像素。这里的画指的是修改图像的三维矩阵。\n",
    "        for index in range(img_some.shape[0]):\n",
    "            img_detect = img_some.iloc[index]\n",
    "        \n",
    "            img_id = img_detect['id']\n",
    "            label = img_detect['class']\n",
    "            x1 = img_detect['x1']\n",
    "            y1 = img_detect['y1']\n",
    "            x2 = img_detect['x2']\n",
    "            y2 = img_detect['y2']\n",
    "            bbs = []\n",
    "            bbs.append(BoundingBox(x1=x1, y1=y1, x2=x2, y2=y2))\n",
    "            bbs_on_img = BoundingBoxesOnImage(bbs, shape=np_img.shape)\n",
    "            np_img = bbs_on_img.draw_on_image(np_img, size=2, color=[0, 255, 0])\n",
    "        \n",
    "        # 最终得到一个numpy array 格式的三维矩阵，可以直接画出来\n",
    "        ia.imshow(np_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们载入已经保存了的预测结果。可以看到我们的结果。class表示类型，serial表示这是这张图类型class的第几个预测框，prob表示网络的自行程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection = \"{}_{}\".format(\n",
    "            model_name,\n",
    "            score_threshold,\n",
    "        )\n",
    "img_pd = pd.read_csv(os.path.join(result_path, detection+\".csv\"), index_col=0)\n",
    "img_pd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们就可以调用之前的函数来观察绘画的结果了。可以看到，在 img_path 下的原始图像上，出现了很多矩形框，这些框将牙齿部分和根管部分框了起来，其精确度相当的高，这就是神经网络的威力了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_box(img_pd, img_path=img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
